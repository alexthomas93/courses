= Build Graph
:order: 11
:type: challenge
:sandbox: true

In the previous task, you split a piece of text into chunks and created embeddings for those chunks.

In this challenge you're going to go a step further and extract nodes and relationships from text in order to build a knowledge graph.

This knowledge graph will capture the entities and relationships within the data.

It will also include the chunks and embeddings as well as their connections to the extracted entities and relationships.

You will use the `neo4j` GraphRAG package for Python driver and OpenAI API for this. 

== Getting Started

Open the `1-knowledge-graphs-vectors\build_graph.py` file in your code editor.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/build_graph.py[]
----

== 1. Creating the Pipeline

First we create the pipeline.

The pipeline allows us to chain the various components, such as text splitters, embedders, and LLM graph extractors together in order to build a knowledge graph.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=create_pipeline]
----

== 2. Chunking the Text

The first step in the pipeline is to split the text into chunks.

We create a text splitter component then add it to the pipeline.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=split_text]
----

== 3. Embedding the Chunks

The next step is to create an embedding for each chunk.

We create a chunk embedder component then add it to the pipeline.

We then connect the text splitter to the embedder to let the pipeline know we want to feed the chunks created by the text splitter into the embedder.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=embed_chunks]
----

== 4. Extracting Nodes and Relationships from the Chunks

Now we use an LLM to extract nodes and relationships from each chunk.

We create a LLM extractor component then add it to the pipeline.

We then connect the embedder to the LLM extractor component to let the pipeline know we want to feed the chunks and their embeddings created by the embedder into the LLM.

We need an embeddings model in order to create embeddings from our chunks.

We can use the OpenAI `text-embedding-3-large` model for this.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=use_llm_extractor]
----

== 5. Creating the Knowledge Graph ===

Finally we upload everything to Neo4j in order to build our knowledge graph.

We first create a Neo4j driver instance to connect to our database.

We create a Neo4j write component then add it to the pipeline.

We then connect the LLM extractor to the Neo4j writer component to let the pipeline know we want to write the nodes, relationships, chunks, and embeddings we extracted in previous steps to the Neo4j database.

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=write_graph]
----

== 6. Running the Pipeline

Finally we feed our input text to the pipeline then run it to create our knowledge graph!

[source, python]
----
include::{repository-raw}/main/1-knowledge-graphs-vectors/solutions/build_graph.py[tag=run_pipeline]
----

== 7. Viewing the Graph

View your graph by running the following command.

[source, cypher]
----
MATCH (c:Chunk)-[]-(n) RETURN *
----

== 8. Bonus Challenges

1. Create a vector index on the `embedding` property of your `Chunk` nodes.
2. Use the `db.index.vector.queryNodes` Cypher procedure to search this property.
3. Create a full text index on the `text` property of your `Chunk` nodes.
4. Use the `db.index.fulltext.queryNodes` Cypher procedure to search this property.

== Continue

When you are ready, you can move on to the next task.

read::Move on[]
[.summary]
== Summary

You created a graph of the course content using the `neo4j` GraphRAG package for Python and the OpenAI API.