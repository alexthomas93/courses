= VectorRetriever
:order: 2
:type: challenge
:sandbox: true:

== Understanding VectorRetriever

The VectorRetriever retrieves relevant nodes from your Neo4j recommendations database based on vector similarity using a vector index built over vector embeddings.

=== How It Works

*Query Embedding*: Converts the user's query into a vector using an embedding model.

*Similarity Search*: Finds nodes with embeddings similar to the query vector.
Retrieval: Returns the top relevant nodes to augment the language model's response.

== When to Use VectorRetriever

*Semantic Search*: Finding nodes based on content meaning, not just keywords.

*Unstructured Data*: Your graph contains text-rich nodes like products, reviews, or descriptions.

*Precomputed Embeddings*: Nodes have embeddings stored as properties.

== Setting Up VectorRetriever

Follow these steps to set up and use the VectorRetriever.

=== Step 1: Install Required Libraries

Install necessary Python packages:

[source, bash]
pip install neo4j-graphrag neo4j openai

=== Step 2: Connect to Your Neo4j Database

Establish a connection using the Neo4j Python driver:

[source, python]
from neo4j import GraphDatabase
uri = "neo4j://localhost:7687"
username = "neo4j"
password = "recommendations"
driver = GraphDatabase.driver(uri, auth=(username, password))

Placeholder for Image: Neo4j Connection Diagram

=== Step 3: Set Up the Embedding Function

Define a function to generate query embeddings using OpenAI's model:

[source, python]
----
from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings

embedder = OpenAIEmbeddings(model="text-embedding-ada-002")
----

=== Step 4: Initialize the VectorRetriever

Create an instance of VectorRetriever:

[source, python]
----
from neo4j_graphrag import VectorRetriever

retriever = VectorRetriever(
    driver,
    index_name="moviePlotsEmbedding",
    embedder=embedder,
    return_properties=["title", "plot"],
)
----

== Example in Action

Assume you have a recommendations database with movies, each having an embedding property.

=== Running the Retriever

Given a query, VectorRetriever finds semantically similar movies:

[source, python]
----
from neo4j_graphrag.generation import GraphRAG

llm = OpenAILLM(model_name="gpt-4o", model_params={"temperature": 0})
rag = GraphRAG(retriever=retriever, llm=llm)
query_text = "A movie about the famous Titanic ship"
response = rag.search(query_text=query_text, retriever_config={"top_k": 5})
print(response.answer)
----

=== Expected Output
----
Movie: Titanic
Movie: Night to Remember
Movie: Titanic
----

== Tips for Effective Use

*Consistent Embeddings*: Use the same model for query and node embeddings.
Vector Indexing: Create a vector index in Neo4j on the embedding property to speed up searches.
*Adjust top_k*: Set top_k based on the number of desired results.


== Next Steps

In the next lesson, you'll learn how to build a GraphRAG pipeline using the VectorRetriever.

read::Continue to Building a GraphRAG Pipeline[]

[.summary]
== Summary

You've learned how to use VectorRetriever for semantic searches in Neo4j, enhancing your RAG pipeline by providing relevant data to language models.
