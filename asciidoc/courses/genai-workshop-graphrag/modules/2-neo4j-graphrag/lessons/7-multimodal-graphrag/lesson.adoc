= Multimodal Retrieval with VectorCypherRetriever
:order: 7
:type: lesson
:sandbox: true

== Recap and Introduction

Previously, you've explored various retrieval strategies using Neo4j, including `VectorRetriever`, `VectorCypherRetriever`, `HybridRetriever`, `HybridCypherRetriever`, and `Text2CypherRetriever` to fetch semantically relevant data. Now, we'll enhance your GraphRAG applications with a multimodal approach using the `VectorCypherRetriever`. This retriever integrates both textual and visual data, enabling more powerful and accurate queries.

== Key Components
image:images/homeward-bound.png[Homeward Bound,width=900,align=center]

* **Image Embeddings**:
  - Generated using the "clip-ViT-B-32" model from Sentence Transformers.
  - Capture visual features of movie posters for semantic similarity.

* **Vector Index**:
  - Utilize the `moviePostersEmbedding` vector index.
  - Stores embeddings of movie posters, enabling efficient image-based searches.

* **Multimodal Integration**:
  - Combines text-based plot descriptions with image-based poster analysis.
  - Allows retrieval based on both semantic content and visual representation.

== Next Steps

Implement the `VectorCypherRetriever` in your script by integrating image embeddings and leveraging the `moviePostersEmbedding` index. This will enable you to perform advanced multimodal searches, enhancing the capabilities of your GraphRAG pipeline.

read::Continue to Building a GraphRAG Pipeline[]
